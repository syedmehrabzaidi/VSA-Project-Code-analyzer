{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lizard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d871ebc0ab5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTTPBasicAuth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mAnalysis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRadon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mGit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGitCL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mHelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJSON\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCommit\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Software-Code-Assessment-FYP-master\\Analysis.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mHelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCommandLine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlizard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mradon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lizard'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "from Analysis import Radon\n",
    "from Git import GitCL\n",
    "from Helpers import File, JSON, Commit\n",
    "from Persistence import Persistence\n",
    "\n",
    "PAGINATION = 100\n",
    "\n",
    "\n",
    "def harvest_repositories(username, password):\n",
    "    i = 1\n",
    "    curr_repo_count = -1\n",
    "    curated_repos = []\n",
    "\n",
    "    url = \"https://api.github.com/search/repositories?q=language:python&order=desc&page=\" + str(i)\n",
    "    req = requests.get(url, auth=HTTPBasicAuth(username, password)).json()\n",
    "    repo_count = req[\"total_count\"]\n",
    "\n",
    "    # debug sentinel cap of n pages of repositories\n",
    "    while curr_repo_count != 0:\n",
    "        url = \"https://api.github.com/search/repositories?q=language:python&order=desc\" + \\\n",
    "              \"&page=\" + str(i) + \"&per_page=\" + str(PAGINATION)\n",
    "        req = requests.get(url, auth=HTTPBasicAuth(username, password))\n",
    "\n",
    "        repo_curation = req.json()\n",
    "        curr_repo_count = len(repo_curation)\n",
    "\n",
    "        print(\"Retrieved commit pagination\", \"(\" + str(PAGINATION * i) + \")\", \"...\")\n",
    "\n",
    "        for j, item in enumerate(repo_curation[\"items\"]):\n",
    "            print(item)\n",
    "            curated_repos.append([item[\"owner\"][\"login\"], item[\"name\"]])\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    return repo_count, curated_repos\n",
    "\n",
    "\n",
    "def iterate_over_commits(repo_name, repo_account, commit_list, arguments):\n",
    "    # invert list to iterate from start to end\n",
    "    commit_list = list(reversed(commit_list))\n",
    "    print(\"Analysing\", str(len(commit_list)), \"commits\", \"...\")\n",
    "\n",
    "    # drop already existing tables to scrub properly\n",
    "    persistence = Persistence()\n",
    "    persistence.purge_db(repo_name)\n",
    "\n",
    "    # set oldest commit first\n",
    "    GitCL.set_repo_commit(repo_name, commit_list[0][1])\n",
    "    total_commits = []\n",
    "\n",
    "    # inverted traversal of the commit list (oldest to newest)\n",
    "    for i, commit in enumerate(commit_list):\n",
    "        # hash the identity to mask the author's identity\n",
    "        # remove this to show real email addresses in data/graphs\n",
    "        commit[2] = str(Commit.obfuscate_identity(commit[2]))\n",
    "\n",
    "        head = commit[1]\n",
    "        author = commit[2]\n",
    "        time = commit[3]\n",
    "        version = str(i + 1)\n",
    "\n",
    "        # --hard reset to sha head\n",
    "        print(\"\\nCommit \" + version, head, author, time)\n",
    "        GitCL.set_repo_commit(repo_name, head)\n",
    "\n",
    "        # remove this before demo\n",
    "        # print(Commit.deobfuscate_identity(author), \"has been hashed to\", author)\n",
    "\n",
    "        # iterate through files changed to get score\n",
    "        print(\"Appending metrics for commit\", head)\n",
    "\n",
    "        generate_radon_stats(repo_account, repo_name, commit, persistence, i + 1, len(commit_list), arguments)\n",
    "        total_commits.append(commit)\n",
    "\n",
    "\n",
    "# generate metrics per commit via radon halstead analysis\n",
    "def generate_radon_stats(repo_account, repo_name, commit, persistence, index, max_iterations, arguments):\n",
    "    print(\"Exporting metrics for\", repo_name, \"to DB ...\")\n",
    "\n",
    "    # note that this is updated per iteration -- avoids horrendous amount of aggregate left joins across dbs\n",
    "    record_repo(index, max_iterations, repo_account, repo_name, persistence)\n",
    "\n",
    "    \"\"\"\n",
    "    Generate according to cmd line arguments\n",
    "    --commits-only\n",
    "    --get-maintainability\n",
    "    \"\"\"\n",
    "    if \"--commits-only\" in arguments:\n",
    "        determine_commit_details(repo_name, commit, persistence, index, max_iterations)\n",
    "    elif \"--get-maintainability\" in arguments:\n",
    "        # warning -- subsequent overhead in generating maintainability indices!\n",
    "        # prepare for a long wait d(^_^)b\n",
    "        determine_commit_details(repo_name, commit, persistence, index, max_iterations)\n",
    "        determine_average_complexity(repo_name, commit, persistence)\n",
    "        determine_cyclomatic_complexity(repo_name, commit, persistence, index, max_iterations)\n",
    "        determine_maintainability(repo_name, commit, persistence)\n",
    "        determine_raw_metrics(repo_name, commit, persistence, index, max_iterations)\n",
    "    elif len(arguments) is 0:\n",
    "        determine_commit_details(repo_name, commit, persistence, index, max_iterations)\n",
    "        determine_average_complexity(repo_name, commit, persistence)\n",
    "        determine_cyclomatic_complexity(repo_name, commit, persistence, index, max_iterations)\n",
    "        determine_raw_metrics(repo_name, commit, persistence, index, max_iterations)\n",
    "\n",
    "\n",
    "def record_repo(index, max_iterations, repo_account, repo_name, persistence):\n",
    "    record = persistence.get_constrained_data(\"jobs\", Persistence.REPOS_COL,\n",
    "                                              {\"repo_name\": repo_name, \"account\": repo_account})\n",
    "\n",
    "    new_data = dict()\n",
    "    new_data[\"account\"] = repo_account\n",
    "    new_data[\"repo_name\"] = repo_name\n",
    "    new_data[\"max_iterations\"] = max_iterations\n",
    "    new_data[\"iteration\"] = index\n",
    "\n",
    "    if record is not None:\n",
    "        persistence.clear_jobs_w_constraint({\"repo_name\": repo_name, \"account\": repo_account})\n",
    "\n",
    "    persistence.insert_document(new_data, \"jobs\", Persistence.REPOS_COL)\n",
    "\n",
    "\n",
    "def determine_commit_details(repo_name, commit, persistence, index, max_iterations):\n",
    "    persistence.insert_document(File.get_commit_details(repo_name, commit, index, max_iterations),\n",
    "                                repo_name, Persistence.COMMITS_COL)\n",
    "\n",
    "\n",
    "def determine_average_complexity(repo_name, commit, persistence):\n",
    "    average_complexity = Radon.get_average_complexity(repo_name, commit)\n",
    "    persistence.insert_document(average_complexity[0], repo_name, Persistence.AVG_COMPLEXITY_COL)\n",
    "\n",
    "\n",
    "def determine_cyclomatic_complexity(repo_name, commit, persistence, index, max_iterations):\n",
    "    cyclomatic_metrics = Radon.get_cyclomatic_complexity(repo_name, commit, index, max_iterations)\n",
    "\n",
    "    # gets the metrics for complexities over functions per file per commit\n",
    "    for metric in cyclomatic_metrics:\n",
    "        for file in metric:\n",
    "            curr_file = metric[file]\n",
    "            if type(curr_file) == list:\n",
    "                for item in curr_file:\n",
    "                    item[\"commit\"] = commit[1]\n",
    "                    persistence.insert_document(item, repo_name, Persistence.CYCLOMATIC_COMPLEXITY_COL)\n",
    "\n",
    "\n",
    "def determine_raw_metrics(repo_name, commit, persistence, index, max_iteration):\n",
    "    raw_metrics = Radon.get_raw_metrics(repo_name, commit[1], index, max_iteration)\n",
    "\n",
    "    del raw_metrics[0]\n",
    "\n",
    "    raw_insert = dict()\n",
    "    raw_items = list()\n",
    "\n",
    "    for file in raw_metrics[0]:\n",
    "        if os.path.splitext(file)[1] == \".py\":\n",
    "            metric = raw_metrics[0][file]\n",
    "            metric[\"file\"] = repo_name + \"/\" + file\n",
    "            raw_items.append(metric)\n",
    "\n",
    "    raw_insert[\"files\"] = raw_items\n",
    "    raw_insert[\"commit\"] = commit[1]\n",
    "\n",
    "    persistence.insert_document(raw_insert, repo_name, Persistence.RAW_METRICS_COL)\n",
    "\n",
    "\n",
    "def determine_maintainability(repo_name, commit, persistence):\n",
    "    # iterate over all files rather than one huge chunk\n",
    "    for path, subdirs, files in os.walk(repo_name):\n",
    "        for name in files:\n",
    "            file_path = os.path.join(path, name)\n",
    "            if fnmatch(name, \"*.py\"):\n",
    "                maintainability_metrics = Radon.get_file_maintainability_index(file_path)\n",
    "\n",
    "                # remove the .py extension\n",
    "                maintainability_metrics[0] = {os.path.splitext(file_path)[0]: maintainability_metrics[0][file_path]}\n",
    "                maintainability_metrics[0][\"commit\"] = commit[1]\n",
    "\n",
    "                JSON.pretty_print_json(maintainability_metrics[0])\n",
    "                persistence.insert_document(maintainability_metrics[0], repo_name, Persistence.MAINTAINABILITY_COL)\n",
    "\n",
    "\n",
    "def print_collection(repo_name, persistence, collection):\n",
    "    for complexity in persistence.get_all_data(repo_name, collection):\n",
    "        print(complexity)\n",
    "\n",
    "\n",
    "def get_repo_data(repo_name, repo_account, commit_list):\n",
    "    username, password = GitCL.get_auth_details()\n",
    "\n",
    "    i = 1\n",
    "    curr_commit_count = -1\n",
    "\n",
    "    print(\"Getting commits for\", repo_account, \"/\", repo_name, \"...\")\n",
    "\n",
    "    while curr_commit_count != 0:\n",
    "        url = \"http://api.github.com/repos/\" + repo_account + \"/\" + repo_name + \\\n",
    "              \"/commits?per_page=\" + str(PAGINATION) + \"&page=\" + str(i)\n",
    "        req = requests.get(url, auth=HTTPBasicAuth(username, password))\n",
    "\n",
    "        json_full_history = req.json()\n",
    "        curr_commit_count = len(json_full_history)\n",
    "\n",
    "        print(\"Retrieved commit pagination\", \"(\" + str(PAGINATION * i) + \")\", \"...\")\n",
    "\n",
    "        for j, item in enumerate(json_full_history):\n",
    "            if item[\"author\"] is not None:\n",
    "                commit_list.append(\n",
    "                    [item[\"sha\"],\n",
    "                     item[\"sha\"][0:7],\n",
    "                     item[\"commit\"][\"author\"][\"email\"],\n",
    "                     item[\"commit\"][\"author\"][\"date\"]])\n",
    "\n",
    "            if not os.path.isdir(repo_name):\n",
    "                GitCL.clone_repo(repo_account, repo_name)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "\n",
    "def harvest_github():\n",
    "    username, password = GitCL.get_auth_details()\n",
    "\n",
    "    # mass harvesting, uncomment to curate all python repos on GitHub\n",
    "    # repos is a list of curated [repo_name, repo_account] of length ~1,511,164\n",
    "    # must change to harvest a pagination, process, store, continue with second pagination ...\n",
    "    repo_count, repos_curated = harvest_repositories(username, password)\n",
    "\n",
    "    for i, repo in enumerate(repos_curated):\n",
    "        print(\"Repo\", str(i), \"/\", repo_count)\n",
    "\n",
    "        commit_list = []\n",
    "        repo_account, repo_name = repo[0], repo[1]\n",
    "        get_repo_data(repo_name, repo_account, commit_list)\n",
    "        iterate_over_commits(repo_name, repo_account, commit_list)\n",
    "\n",
    "\n",
    "def harvest_repo():\n",
    "    commit_list = []\n",
    "\n",
    "    repo_account = sys.argv[1]\n",
    "    repo_name = sys.argv[2]\n",
    "\n",
    "    \"\"\"\n",
    "    --commits-only\n",
    "    --show-identities\n",
    "    --get-maintainability\n",
    "    \"\"\"\n",
    "    arguments = []\n",
    "    if len(sys.argv) > 2:\n",
    "        arguments = sys.argv[3:]\n",
    "\n",
    "    get_repo_data(repo_name, repo_account, commit_list)\n",
    "    iterate_over_commits(repo_name, repo_account, commit_list, arguments)\n",
    "\n",
    "\n",
    "def main():\n",
    "    harvest_repo()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lizard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fc94debe9669>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mHelpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCommandLine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlizard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mradon\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lizard'"
     ]
    }
   ],
   "source": [
    "from Helpers import CommandLine, File\n",
    "\n",
    "import lizard\n",
    "import radon\n",
    "import re\n",
    "\n",
    "\n",
    "class Sonar:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def sonar_analysis(repo_dir, version):\n",
    "        CommandLine.execute_cmd_print(\n",
    "            \"cd \" + repo_dir + \"; sonar-scanner -Dsonar.sources=. -Dsonar.projectKey=\" + repo_dir +\n",
    "            \" -Dsonar.projectVersion=\" + str(version))\n",
    "\n",
    "    @staticmethod\n",
    "    def purge_repo_analysis(project):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Lizard:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cyclomatic_complexity(repo):\n",
    "        results = lizard.analyze(\"./\" + repo, None, 2)\n",
    "        print(results.__dict__)\n",
    "\n",
    "\n",
    "class Radon:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def analyse_code(repo):\n",
    "        result = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc *\").decode(\n",
    "            \"utf-8\").split(\"\\n\")\n",
    "        return result[len(result) - 1]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cyclomatic_complexity(repo, commit, iteration, max_iteration):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc * -s -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_commit_details(repo, commit, iteration, max_iteration))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_cyclomatic_complexity(file):\n",
    "        results = CommandLine.execute_cmd_get_result(\"radon cc -s -j ./\" + file).decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_raw_metrics(repo, commit, index, max_iteration):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon raw * -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "        metrics = list()\n",
    "\n",
    "        metrics.append(File.get_commit_details(repo, commit, index, max_iteration))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_maintainability_index(repo, commit, index, max_iterations):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon mi * -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_commit_details(repo, commit, index, max_iterations))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_maintainability_index(file):\n",
    "        results = CommandLine.execute_cmd_get_result(\"radon mi -j \" + file).decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_average_complexity(repo, commit):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc * --total-average\").decode(\n",
    "            \"utf-8\").split(\"\\n\")\n",
    "        complexity = results[len(results) - 1]\n",
    "        complexity = re.search(\"\\d+\\.?\\d*\", complexity).group(0)\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append({\"commit_head\": commit[1]})\n",
    "        metrics[0][\"avg_complexity\"] = complexity\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lizard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0da3271f8931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlizard\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lizard'"
     ]
    }
   ],
   "source": [
    "import lizard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Helpers import CommandLine, File\n",
    "\n",
    "import lizard\n",
    "import radon\n",
    "import re\n",
    "\n",
    "\n",
    "class Sonar:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def sonar_analysis(repo_dir, version):\n",
    "        CommandLine.execute_cmd_print(\n",
    "            \"cd \" + repo_dir + \"; sonar-scanner -Dsonar.sources=. -Dsonar.projectKey=\" + repo_dir +\n",
    "            \" -Dsonar.projectVersion=\" + str(version))\n",
    "\n",
    "    @staticmethod\n",
    "    def purge_repo_analysis(project):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Lizard:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cyclomatic_complexity(repo):\n",
    "        results = lizard.analyze(\"./\" + repo, None, 2)\n",
    "        print(results.__dict__)\n",
    "\n",
    "\n",
    "class Radon:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def analyse_code(repo):\n",
    "        result = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc *\").decode(\n",
    "            \"utf-8\").split(\"\\n\")\n",
    "        return result[len(result) - 1]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_cyclomatic_complexity(repo, commit, iteration, max_iteration):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc * -s -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_commit_details(repo, commit, iteration, max_iteration))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_cyclomatic_complexity(file):\n",
    "        results = CommandLine.execute_cmd_get_result(\"radon cc -s -j ./\" + file).decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_raw_metrics(repo, commit, index, max_iteration):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon raw * -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "        metrics = list()\n",
    "\n",
    "        metrics.append(File.get_commit_details(repo, commit, index, max_iteration))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_maintainability_index(repo, commit, index, max_iterations):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon mi * -j\").decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_commit_details(repo, commit, index, max_iterations))\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_file_maintainability_index(file):\n",
    "        results = CommandLine.execute_cmd_get_result(\"radon mi -j \" + file).decode(\"utf-8\").split(\"\\n\")\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append(File.get_json_from_cmd(results))\n",
    "        return metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def get_average_complexity(repo, commit):\n",
    "        results = CommandLine.execute_cmd_get_result(\"cd \" + repo + \"; radon cc * --total-average\").decode(\n",
    "            \"utf-8\").split(\"\\n\")\n",
    "        complexity = results[len(results) - 1]\n",
    "        complexity = re.search(\"\\d+\\.?\\d*\", complexity).group(0)\n",
    "\n",
    "        metrics = list()\n",
    "        metrics.append({\"commit_head\": commit[1]})\n",
    "        metrics[0][\"avg_complexity\"] = complexity\n",
    "\n",
    "        return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymongo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-25c094baf42a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPersistence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mREPOS_COL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"repos\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymongo'"
     ]
    }
   ],
   "source": [
    "from pymongo import *\n",
    "\n",
    "\n",
    "class Persistence:\n",
    "    REPOS_COL = \"repos\"\n",
    "    COMMITS_COL = \"commits\"\n",
    "    AVG_COMPLEXITY_COL = \"average_complexity\"\n",
    "    CYCLOMATIC_COMPLEXITY_COL = \"cyclomatic_complexity\"\n",
    "    MAINTAINABILITY_COL = \"maintainability\"\n",
    "    RAW_METRICS_COL = \"raw_metrics\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = MongoClient('mongodb://localhost:27017/code_analysis')\n",
    "\n",
    "    def insert_document(self, new_doc, repo, col):\n",
    "        db = self.client[repo]\n",
    "        db[col].insert_one(new_doc)\n",
    "\n",
    "    def update_document(self, new_doc, repo, col):\n",
    "        db = self.client[repo]\n",
    "        db[col].save(new_doc)\n",
    "\n",
    "    def insert_documents(self, new_docs, repo, col):\n",
    "        db = self.client[repo]\n",
    "        db[col].insert(new_docs)\n",
    "\n",
    "    def get_all_data(self, repo, col):\n",
    "        db = self.client[repo]\n",
    "        return db[col].find().sort(\"time\")\n",
    "\n",
    "    def get_constrained_data(self, repo, col, constraint):\n",
    "        db = self.client[repo]\n",
    "        return db[col].find_one(constraint)\n",
    "\n",
    "    def purge_db(self, repo=None, col=None):\n",
    "        db = self.client\n",
    "\n",
    "        if col is None:\n",
    "            db.drop_database(repo)\n",
    "        else:\n",
    "            db[repo][col].drop_collection(col)\n",
    "\n",
    "    def clear_jobs_w_constraint(self, constraint):\n",
    "        db = self.client\n",
    "        db[\"jobs\"][\"repos\"].delete_many(constraint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit (virtualenv)",
   "language": "python",
   "name": "python36564bitvirtualenv06cc43a6842d498d9f1a5b933184b2fe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
